

import numpy as np
import pandas as pd
import urllib
import urllib3
import requests

f = open(r"C:\Users\93541\Desktop\数据分析联系\100-Days-Of-ML-Code-master\datasets\Data.csv" )
dataset = pd.read_csv(f )

### 在使用绝对路径含中文时报错时可不直接套用dataset = pd.read_scv（url），可如上所使###
print(dataset)

X = dataset.iloc[ : , :-1].values
Y = dataset.iloc[ : , 3].values

### sklearn处理missing data；mean代替nan###

from sklearn.preprocessing import Imputer, LabelEncoder, OneHotEncoder,StandardScaler
imputer = Imputer(missing_values = "NaN", strategy = "mean", axis = 0)
imputer = imputer.fit(X[ : , 1:3])
X[ : , 1:3] = imputer.transform(X[ : , 1:3])

labelencoder_X = LabelEncoder()
X[ : , 0] = labelencoder_X.fit_transform(X[ : , 0])

labelencoder_Y = LabelEncoder()
Y =  labelencoder_Y.fit_transform(Y)

onehotencoder = OneHotEncoder(categorical_features = [0])
X = onehotencoder.fit_transform(X).toarray()

###Splitting datasets into train and test###
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split( X , Y , test_size = 0.2, random_state = 0)


###scale###
sc_X = StandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.fit_transform(X_test)
